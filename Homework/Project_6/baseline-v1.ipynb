{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":34288,"databundleVersionId":3207826,"sourceType":"competition"}],"dockerImageVersionId":30157,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <center> Практика. EDA + Feature Engineering. Соревнование на Kaggle </center>\r\n\r\n### **Постановка задачи:**\r\n\r\n**ИССЛЕДОВАНИЕ ДАННЫХ:**\r\n\r\n✍ В этом модуле мы будем работать с датасетом, в котором содержатся сведения о 515 000 отзывов на отели Европы. Модель, которую мы будем обучать, должна предсказывать рейтинг отеля по данным сайта Booking на основе имеющихся в датасете данных.\r\n\r\n***ДАННЫЕ САЙТА BOOKING:***\r\n\r\nНаименование столбца:  | Описание столбца:\r\n------- | --------\r\n***hotel_address***   | адрес отеля;\r\n***review_date***   | дата, когда рецензент разместил соответствующий отзыв;\r\n***average_score***   | средний балл отеля, рассчитанный на основе последнего комментария за последний год;\r\n***hotel_name***   | название отеля;\r\n***reviewer_nationality***   | страна рецензента;\r\n***negative_review***   | отрицательный отзыв, который рецензент дал отелю;\r\n***review_total_negative_word_counts***   | общее количество слов в отрицательном отзыв;\r\n***positive_review***   | положительный отзыв, который рецензент дал отелю;\r\n***review_total_positive_word_counts***   | общее количество слов в положительном отзыве.\r\n***reviewer_score***   | оценка, которую рецензент поставил отелю на основе своего опыта;\r\n***total_number_of_reviews_reviewer_has_given***   | количество отзывов, которые рецензенты дали в прошлом;\r\n***total_number_of_reviews***   | общее количество действительных отзывов об отеле;\r\n***tags***   | теги, которые рецензент дал отелю;\r\n***days_since_review***   | количество дней между датой проверки и датой очистки;\r\n***additional_number_of_scoring***   | есть также некоторые гости, которые просто поставили оценку сервису, но не оставили отзыв. Это число указывает, сколько там действительных оценок без проверки.\r\n***lat***   | географическая широта отеля;\r\n***lng***   | географическая долгота отеля.","metadata":{}},{"cell_type":"markdown","source":"***Содержание работы:***\r\n\r\n1. Импорт библиотек и загрузка данных.\r\n2. Очистка данных.\r\n3. Исследование данных.\r\n4. Генерация признаков.\r\n5. Преобразование признаков.\r\n6. Отбор признаков.\r\n7. Обучение модели.","metadata":{}},{"cell_type":"markdown","source":"## **1. Импорт библиотек и загрузка данных:**","metadata":{}},{"cell_type":"code","source":"# Загружаем необходимые библиотеки:\n\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# импортируем библиотеки для визуализации\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n# Загружаем специальный удобный инструмент для разделения датасета:\nfrom sklearn.model_selection import train_test_split\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# всегда фиксируйте RANDOM_SEED, чтобы ваши эксперименты были воспроизводимы!\nRANDOM_SEED = 42","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# зафиксируем версию пакетов, чтобы эксперименты были воспроизводимы:\n!pip freeze > requirements.txt","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Подгрузим наши данные из соревнования\n\nDATA_DIR = '/kaggle/input/sf-booking/'\ndf_train = pd.read_csv(DATA_DIR+'/hotels_train.csv') # датасет для обучения\ndf_test = pd.read_csv(DATA_DIR+'hotels_test.csv') # датасет для предсказания\nsample_submission = pd.read_csv(DATA_DIR+'/submission.csv') # самбмишн","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train.head(2)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_test.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_test.head(2)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sample_submission.head(2)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sample_submission.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ВАЖНО! дря корректной обработки признаков объединяем\n# трейн и тест в один датасет:\n\ndf_train['sample'] = 1 # помечаем где у нас трейн\ndf_test['sample'] = 0 # помечаем где у нас тест\ndf_test['reviewer_score'] = 0 # в тесте у нас нет значения reviewer_score,\n# мы его должны предсказать, по этому пока просто заполняем нулями\n\ndata = df_test.append(df_train, sort=False).reset_index(drop=True)\n# объединяем","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data['lat'] = data['lat'].fillna(0, inplace=True)\ndata['lng'] = data['lng'].fillna(0, inplace=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data.nunique(dropna=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (15,10)\nsns.heatmap(data.drop(['sample'], axis=1).corr(), annot=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### ***Вывод:*** в датасете 515738 записей (есть пропущенные значения).","metadata":{}},{"cell_type":"markdown","source":"## **2. Очистка данных:**\n\n2.1. Проверим данные на наличие дубликатов и удалим найденные дубликаты:","metadata":{}},{"cell_type":"code","source":"print('В датасете в тренировочной выборке: {} дубликатов.'.format(df_train[df_train.duplicated()].shape[0]))\nprint('В датасете в тестовой выборке: {} дубликатов.'.format(df_test[df_test.duplicated()].shape[0]))\n\ndf_train.drop_duplicates(inplace=True)\nprint('Количество строк после удаления дубликатов в тренировочной выборке составляет: {}.'.format(df_train.shape[0]))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### ***Вывод:*** найдены дубликаты в обеих частях датасета мы проведем удаление дубликатов, только в тренировочной выборке (представленные данные содержат 307 дубликатов), т.к. тестовая выборка фиксирована и ее изменять нельзя по правилам соревнования на kaggle. Количество строк после удаления дубликатов в тренировочной выборке составляет 386496.","metadata":{}},{"cell_type":"markdown","source":"## **3. Исследование данных:**\n\n3.1. Классифицируем все признаки на числовые и категориальные:\n\n***Категориальные признаки:***\n1. hotel_address\n2. review_date\n3. hotel_name\n4. reviewer_nationality\n5. negative_review\n6. positive_review\n7. tags\n8. days_since_review\n\n***Числовые признаки:***\n1. additional_number_of_scoring\n2. average_score\n3. review_total_negative_word_counts\n4. total_number_of_reviews\n5. review_total_positive_word_counts\n6. total_number_of_reviews_reviewer_has_given\n7. lat\n8. lng\n9. sample\n10. reviewer_score\n\n3.2. Выведем на экран основные статистические характеристики\nданных по каждому числовому признаку:","metadata":{}},{"cell_type":"code","source":"data.describe(include = 'all')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **Вывод:** с помощью метода describe() определили основные статистические характеристики для каждого из признаков.","metadata":{}},{"cell_type":"markdown","source":"## **4. Генерация признаков:**\n\n4.1. Иследуем признак hotel_address и создадим новые признаки ***'country'*** - страна, ***'city'*** - город, ***'hotel_city_count'*** - количество отелей в городе:","metadata":{}},{"cell_type":"code","source":"# Создание нового признака 'country':\n\ndata['country'] = data['hotel_address'].apply(lambda x: x.split()[-1] \n        if x.split()[-1] != 'Kingdom' \n        else ' '.join(x.split()[-2:]))\n\nprint('\\n В датасете представлены отели из '+ str(\n    data['country'].nunique()) + ' стран:\\n')\nprint(data['country'].value_counts())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Создание нового признака 'city':\n\ndata['city'] = data.apply(lambda x: x['hotel_address'].split()[-5] \n        if x['country'] == 'United Kingdom'\n        else x['hotel_address'].split()[-2], axis=1)\n\nprint('\\n В датасете представлены отели из '+ str(\n    data['city'].nunique()) + ' городов:\\n')\nprint(data['city'].value_counts())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Создание нового числового признака 'hotel_city_count':\n\ndata['hotel_city_count'] = data.groupby(\n    'city')['hotel_name'].transform('count')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Кодируем признаки методом OneHotEncoding:\n\ndata = pd.get_dummies(data, columns = ['country'])\ndata = pd.get_dummies(data, columns = ['city'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"4.2. Иследуем признак 'review_date'. Приведем дату отзыва к формату datetime.\nСоздадим новые числовые признаки:\n\n***'review_year'*** - год;  \n***'review_month'*** - месяц;  \n***'review_quarter'*** - квартал;  \n***'review_season'*** - сезон, в котором рецензент разместил соответствующий отзыв","metadata":{}},{"cell_type":"code","source":"# Приведем дату отзыва к формату datetime:\n\ndata['review_date'] = pd.to_datetime(data['review_date']).dt.date\n\n# Выделим год, месяц, квартал из даты отзыва:\n\ndata['review_year'] = pd.to_datetime(data['review_date']).dt.year\ndata['review_month'] = pd.to_datetime(data['review_date']).dt.month\ndata['review_quarter'] = pd.to_datetime(data['review_date']).dt.quarter\n\n# Создание нового признака 'review_season':\n\ndata['review_season'] = data['review_month']\n\ndef get_season(month):\n    \"\"\"function for defenition of season for date review\"\"\"\n    \n    if month in list(range(3,6)):\n        return 'spring'\n    \n    if month in list(range(6,9)):\n        return 'summer'\n    \n    if month in list(range(9,12)):\n        return 'autumn'\n    \n    else:\n        return 'winter'\n\ndata['review_season'] = data['review_season'].apply(get_season)\n\n# Кодируем признак методом OneHotEncoding:\n\ndata = pd.get_dummies(data, columns=['review_season'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Выделим сеззоность оценок:\n\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 4))\n\nsns.countplot(data['review_month'], ax=axes[0]);\naxes[0].set(xlabel='Месяц:', ylabel='Количество записей:')\naxes[0].set_title('Распределение данных по месяцам:')\n\nsns.countplot(data['review_quarter'],  ax=axes[1]);\naxes[1].set(xlabel='Квартал:', ylabel='Количество записей:')\naxes[1].set_title('Распределение данных по кварталам:')\nfig.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"4.3 Иследуем признак 'tags' и создадим новый числовой признак ***'nights'*** - количество ночей в отеле:","metadata":{}},{"cell_type":"code","source":"data['tags'] = data['tags'].apply(\n    lambda x: x.replace(\"[' \", \"\").replace(\" ']\", \"\").split(\" ', ' \"))\n\ndef get_night(arg):\n    \n    for tag in arg:\n        if 'Stayed' in tag:\n            return int(tag.split()[1])\n            \n# Создание нового признака 'nights':\ndata['nights'] = data['tags'].apply(get_night)\n\n# Заменим пропуски в признаке медианой:\ndata['nights'] = data['nights'].fillna(data.nights.median())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"4.4 Иследуем признак 'tags' и создадим новый числовой признак ***'type_trip'*** - тип поездки:","metadata":{}},{"cell_type":"code","source":"# Создание нового признака 'type_trip':\n\ndata['type_trip'] = data['tags'].apply(\n    lambda x: 1 if 'Business' in x else 0)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"4.5 Иследуем признак 'tags' и создадим новый признак ***'type_of_travelers'*** - тип путешественников:","metadata":{}},{"cell_type":"code","source":"def set_why_stayed(value):\n    \n    if 'Group' in  value:\n        return 'Group'\n    if 'Couple' in value:\n        return 'Couple'  \n    if 'Solo traveler' in value:\n        return 'Solo traveler'\n    if 'Family with young children' in value:\n        return 'Family with young children'\n    if 'Family with older children' in value:\n        return 'Family with older children' \n    return np.nan\n\n# Создание нового признака 'type_of_travelers':\n\ndata['type_of_travelers'] = data['tags'].apply(set_why_stayed)\ndata['type_of_travelers'] = data['type_of_travelers'].fillna(\n    data['type_of_travelers'].mode().iat[0])\n\n# Кодируем признак методом OneHotEncoding:\n\ndata = pd.get_dummies(data, columns=['type_of_travelers'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"4.6 Иследуем признак 'tags' и создадим новый признак ***'type_of_apartment'*** - тип путешественников:","metadata":{}},{"cell_type":"code","source":"data['tags'] = data['tags'].apply(\n    lambda x: x.replace(\"[' \", \"\").replace(\" ']\", \"\").split(\" ', ' \"))\n\ndef get_room(arg):\n    \n    for tag in arg:\n        if 'Room' in tag:\n            return tag.strip()\n    return 'Unknown'\n            \n# # Создание нового признака 'type_of_apartment':\n\ndata['type_of_apartment'] = data['tags'].apply(get_room)\n# data['type_of_apartment'].value_counts()\n# data['type_of_apartment'].count()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"4.7 Иследуем признак 'days_since_review' выделим числа:","metadata":{}},{"cell_type":"code","source":"data['days_since_review'] = data['days_since_review'].apply(\n    lambda x: int(x.split()[0]))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"4.8 Иследуем признак 'negative_review' и создадим числовой признак ***'is_negative'*** - отрицательные отзывы, которые не имеют отрицательного значения:","metadata":{}},{"cell_type":"code","source":"# Создание нового признака 'is_negative':\n\ndata['is_negative'] = data['negative_review'].apply(\n    lambda x: 0 if x == 'No Negative' else 1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"4.9 Иследуем признак 'positive_review' и создадим числовой признак ***'is_positive'*** - положительные отзывы, которые не имеют положительного значения:","metadata":{}},{"cell_type":"code","source":"# Создание нового признака 'is_positive':\n\ndata['is_positive'] = data['positive_review'].apply(\n    lambda x: 0 if x =='No Positive' else 1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **6. Отбор признаков:**\n\n6.1. Определим в данных неинформативные признаки, которые не будут участвовать в исследовании:","metadata":{}},{"cell_type":"code","source":"# Удаляем признаки которые еще не успели обработать, \n# модель на признаках с dtypes \"object\" обучаться не будет,\n# просто выберим их и удалим:\n\nobject_columns = [s for s in data.columns if data[s].dtypes == 'object']\ndata.drop(object_columns, axis = 1, inplace=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Теперь выделим тестовую часть:\n\ntrain_data = data.query('sample == 1').drop(['sample'], axis=1)\ntest_data = data.query('sample == 0').drop(['sample'], axis=1)\n\ny = train_data.reviewer_score.values            # наш таргет\nX = train_data.drop(['reviewer_score'], axis=1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **7. Обучение модели**","metadata":{}},{"cell_type":"code","source":"# Воспользуемся специальной функцие train_test_split\n# для разбивки тестовых данных\n# выделим 20% данных на валидацию (параметр test_size):\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=RANDOM_SEED)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Проверяем:\n\ntest_data.shape, train_data.shape, X.shape, X_train.shape, X_test.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Импортируем необходимые библиотеки:\n# инструмент для создания и обучения модели:\n\nfrom sklearn.ensemble import RandomForestRegressor\n\n# инструменты для оценки точности модели:\n\nfrom sklearn import metrics","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Создаём модель (НАСТРОЙКИ НЕ ТРОГАЕМ):\n\nmodel = RandomForestRegressor(\n    n_estimators=100, verbose=1, n_jobs=-1, random_state=RANDOM_SEED)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Обучаем модель на тестовом наборе данных:\n\nmodel.fit(X_train, y_train)\n\n# Используем обученную модель для предсказания\n# рейтинга ресторанов в тестовой выборке.\n# Предсказанные значения записываем в переменную y_pred:\n\ny_pred = model.predict(X_test)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Сравниваем предсказанные значения (y_pred) с реальными (y_test),\n# и смотрим насколько они в среднем отличаются\n# Метрика называется Mean Absolute Error (MAE) и показывает\n# среднее отклонение предсказанных значений от фактических.\n\nprint('MAPE:', metrics.mean_absolute_error(y_test, y_pred))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# в RandomForestRegressor есть возможность вывести\n# самые важные признаки для модели:\n\nplt.rcParams['figure.figsize'] = (10,10)\nfeat_importances = pd.Series(model.feature_importances_, index=X.columns)\nfeat_importances.nlargest(15).plot(kind='barh')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_data.sample(10)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_data = test_data.drop(['reviewer_score'], axis=1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sample_submission","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predict_submission = model.predict(test_data)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predict_submission","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"list(sample_submission)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sample_submission['reviewer_score'] = predict_submission\nsample_submission.to_csv('submission.csv', index=False)\nsample_submission.head(10)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}