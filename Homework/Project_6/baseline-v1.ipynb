{"cells":[{"cell_type":"markdown","metadata":{},"source":["# <center> Практика. EDA + Feature Engineering. Соревнование на Kaggle </center>\n","\n","### **Постановка задачи:**\n","\n","**ИССЛЕДОВАНИЕ ДАННЫХ:**\n","\n","✍ В этом модуле мы будем работать с датасетом, в котором содержатся сведения о 515 000 отзывов на отели Европы. Модель, которую мы будем обучать, должна предсказывать рейтинг отеля по данным сайта Booking на основе имеющихся в датасете данных.\n","\n","***ДАННЫЕ САЙТА BOOKING:***\n","\n","Наименование столбца:  | Описание столбца:\n","------- | --------\n","***hotel_address***   | адрес отеля;\n","***review_date***   | дата, когда рецензент разместил соответствующий отзыв;\n","***average_score***   | средний балл отеля, рассчитанный на основе последнего комментария за последний год;\n","***hotel_name***   | название отеля;\n","***reviewer_nationality***   | страна рецензента;\n","***negative_review***   | отрицательный отзыв, который рецензент дал отелю;\n","***review_total_negative_word_counts***   | общее количество слов в отрицательном отзыв;\n","***positive_review***   | положительный отзыв, который рецензент дал отелю;\n","***review_total_positive_word_counts***   | общее количество слов в положительном отзыве.\n","***reviewer_score***   | оценка, которую рецензент поставил отелю на основе своего опыта;\n","***total_number_of_reviews_reviewer_has_given***   | количество отзывов, которые рецензенты дали в прошлом;\n","***total_number_of_reviews***   | общее количество действительных отзывов об отеле;\n","***tags***   | теги, которые рецензент дал отелю;\n","***days_since_review***   | количество дней между датой проверки и датой очистки;\n","***additional_number_of_scoring***   | есть также некоторые гости, которые просто поставили оценку сервису, но не оставили отзыв. Это число указывает, сколько там действительных оценок без проверки.\n","***lat***   | географическая широта отеля;\n","***lng***   | географическая долгота отеля."]},{"cell_type":"markdown","metadata":{},"source":["***Содержание работы:***\n","\n","1. Импорт библиотек и загрузка данных.\n","2. Очистка данных.\n","3. Исследование данных.\n","4. Генерация признаков.\n","5. Преобразование признаков.\n","6. Отбор признаков.\n","7. Обучение модели."]},{"cell_type":"markdown","metadata":{},"source":["## **1. Импорт библиотек и загрузка данных:**"]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["# Загружаем необходимые библиотеки:\n","\n","# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# импортируем библиотеки для визуализации\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","%matplotlib inline\n","\n","# Загружаем специальный удобный инструмент для разделения датасета:\n","from sklearn.model_selection import train_test_split\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":2,"metadata":{"trusted":true},"outputs":[],"source":["# всегда фиксируйте RANDOM_SEED, чтобы ваши эксперименты были воспроизводимы!\n","RANDOM_SEED = 42"]},{"cell_type":"code","execution_count":3,"metadata":{"trusted":true},"outputs":[],"source":["# зафиксируем версию пакетов, чтобы эксперименты были воспроизводимы:\n","!pip freeze > requirements.txt"]},{"cell_type":"code","execution_count":4,"metadata":{"trusted":true},"outputs":[{"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/kaggle/input/sf-booking//hotels_train.csv'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[1;32mc:\\GitHub\\SkillFactory\\Homework\\Project_6\\baseline-v1.ipynb Cell 7\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/GitHub/SkillFactory/Homework/Project_6/baseline-v1.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Подгрузим наши данные из соревнования\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/GitHub/SkillFactory/Homework/Project_6/baseline-v1.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m DATA_DIR \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/kaggle/input/sf-booking/\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/GitHub/SkillFactory/Homework/Project_6/baseline-v1.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m df_train \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(DATA_DIR\u001b[39m+\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m/hotels_train.csv\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39m# датасет для обучения\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/GitHub/SkillFactory/Homework/Project_6/baseline-v1.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m df_test \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(DATA_DIR\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39mhotels_test.csv\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m# датасет для предсказания\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/GitHub/SkillFactory/Homework/Project_6/baseline-v1.ipynb#W6sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m sample_submission \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(DATA_DIR\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m/submission.csv\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m# самбмишн\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\IK\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n","File \u001b[1;32mc:\\Users\\IK\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    613\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n","File \u001b[1;32mc:\\Users\\IK\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n","File \u001b[1;32mc:\\Users\\IK\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1706\u001b[0m     f,\n\u001b[0;32m   1707\u001b[0m     mode,\n\u001b[0;32m   1708\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1709\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1710\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1711\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1712\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1713\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1714\u001b[0m )\n\u001b[0;32m   1715\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n","File \u001b[1;32mc:\\Users\\IK\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    864\u001b[0m             handle,\n\u001b[0;32m    865\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    866\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    867\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    868\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n","\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/sf-booking//hotels_train.csv'"]}],"source":["# Подгрузим наши данные из соревнования\n","\n","DATA_DIR = '/kaggle/input/sf-booking/'\n","df_train = pd.read_csv(DATA_DIR+'/hotels_train.csv') # датасет для обучения\n","df_test = pd.read_csv(DATA_DIR+'hotels_test.csv') # датасет для предсказания\n","sample_submission = pd.read_csv(DATA_DIR+'/submission.csv') # самбмишн"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df_train.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df_train.head(2)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df_test.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df_test.head(2)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["sample_submission.head(2)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["sample_submission.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# ВАЖНО! дря корректной обработки признаков объединяем\n","# трейн и тест в один датасет:\n","\n","df_train['sample'] = 1 # помечаем где у нас трейн\n","df_test['sample'] = 0 # помечаем где у нас тест\n","df_test['reviewer_score'] = 0 # в тесте у нас нет значения reviewer_score,\n","# мы его должны предсказать, по этому пока просто заполняем нулями\n","\n","data = df_test.append(df_train, sort=False).reset_index(drop=True)\n","# объединяем"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["data.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["data['lat'] = data['lat'].fillna(0, inplace=True)\n","data['lng'] = data['lng'].fillna(0, inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["data.nunique(dropna=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["plt.rcParams['figure.figsize'] = (15,10)\n","sns.heatmap(data.drop(['sample'], axis=1).corr(), annot=True)"]},{"cell_type":"markdown","metadata":{},"source":["### ***Вывод:*** в датасете 515738 записей (есть пропущенные значения)."]},{"cell_type":"markdown","metadata":{},"source":["## **2. Очистка данных:**\n","\n","2.1. Проверим данные на наличие дубликатов и удалим найденные дубликаты:"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print('В датасете в тренировочной выборке: {} дубликатов.'.format(df_train[df_train.duplicated()].shape[0]))\n","print('В датасете в тестовой выборке: {} дубликатов.'.format(df_test[df_test.duplicated()].shape[0]))\n","\n","df_train.drop_duplicates(inplace=True)\n","print('Количество строк после удаления дубликатов в тренировочной выборке составляет: {}.'.format(df_train.shape[0]))"]},{"cell_type":"markdown","metadata":{},"source":["### ***Вывод:*** найдены дубликаты в обеих частях датасета мы проведем удаление дубликатов, только в тренировочной выборке (представленные данные содержат 307 дубликатов), т.к. тестовая выборка фиксирована и ее изменять нельзя по правилам соревнования на kaggle. Количество строк после удаления дубликатов в тренировочной выборке составляет 386496."]},{"cell_type":"markdown","metadata":{},"source":["## **3. Исследование данных:**\n","\n","3.1. Классифицируем все признаки на числовые и категориальные:\n","\n","***Категориальные признаки:***\n","1. hotel_address\n","2. review_date\n","3. hotel_name\n","4. reviewer_nationality\n","5. negative_review\n","6. positive_review\n","7. tags\n","8. days_since_review\n","\n","***Числовые признаки:***\n","1. additional_number_of_scoring\n","2. average_score\n","3. review_total_negative_word_counts\n","4. total_number_of_reviews\n","5. review_total_positive_word_counts\n","6. total_number_of_reviews_reviewer_has_given\n","7. lat\n","8. lng\n","9. sample\n","10. reviewer_score\n","\n","3.2. Выведем на экран основные статистические характеристики\n","данных по каждому числовому признаку:"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["data.describe(include = 'all')"]},{"cell_type":"markdown","metadata":{},"source":["### **Вывод:** с помощью метода describe() определили основные статистические характеристики для каждого из признаков."]},{"cell_type":"markdown","metadata":{},"source":["## **4. Генерация признаков:**\n","\n","4.1. Иследуем признак hotel_address и создадим новые признаки ***'country'*** - страна, ***'city'*** - город, ***'hotel_city_count'*** - количество отелей в городе:"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Создание нового признака 'country':\n","\n","data['country'] = data['hotel_address'].apply(lambda x: x.split()[-1] \n","        if x.split()[-1] != 'Kingdom' \n","        else ' '.join(x.split()[-2:]))\n","\n","print('\\n В датасете представлены отели из '+ str(\n","    data['country'].nunique()) + ' стран:\\n')\n","print(data['country'].value_counts())"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Создание нового признака 'city':\n","\n","data['city'] = data.apply(lambda x: x['hotel_address'].split()[-5] \n","        if x['country'] == 'United Kingdom'\n","        else x['hotel_address'].split()[-2], axis=1)\n","\n","print('\\n В датасете представлены отели из '+ str(\n","    data['city'].nunique()) + ' городов:\\n')\n","print(data['city'].value_counts())"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Создание нового числового признака 'hotel_city_count':\n","\n","data['hotel_city_count'] = data.groupby(\n","    'city')['hotel_name'].transform('count')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Кодируем признаки методом OneHotEncoding:\n","\n","data = pd.get_dummies(data, columns = ['country'])\n","data = pd.get_dummies(data, columns = ['city'])"]},{"cell_type":"markdown","metadata":{},"source":["4.2. Иследуем признак 'reviewer_nationality':"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Выделим десять лидирующих национальностей:\n","\n","nationality10 = data['reviewer_nationality'].value_counts().nlargest(10)\n","\n","data['reviewer_nationality'] = data['reviewer_nationality'].apply(\n","    lambda x: x if x in nationality10 else 'other')\n","\n","fig = plt.figure(figsize = (16,10))\n","barplot = sns.boxplot(\n","    data = data, x = 'reviewer_score',\n","    y = 'reviewer_nationality', orient = 'h')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Кодируем признаки методом OneHotEncoding:\n","\n","data = pd.get_dummies(data, columns = ['reviewer_nationality'])"]},{"cell_type":"markdown","metadata":{},"source":["4.3. Иследуем признак 'review_date'. Приведем дату отзыва к формату datetime.\n","Создадим новые числовые признаки:\n","\n","***'review_year'*** - год;  \n","***'review_month'*** - месяц;  \n","***'review_quarter'*** - квартал;  \n","***'review_season'*** - сезон, в котором рецензент разместил соответствующий отзыв"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Приведем дату отзыва к формату datetime:\n","\n","data['review_date'] = pd.to_datetime(data['review_date']).dt.date\n","\n","# Выделим год, месяц, квартал из даты отзыва:\n","\n","data['review_year'] = pd.to_datetime(data['review_date']).dt.year\n","data['review_month'] = pd.to_datetime(data['review_date']).dt.month\n","data['review_quarter'] = pd.to_datetime(data['review_date']).dt.quarter\n","\n","# Создание нового признака 'review_season':\n","\n","data['review_season'] = data['review_month']\n","\n","def get_season(month):\n","        \n","    if month in list(range(3,6)):\n","        return 'spring'\n","    \n","    if month in list(range(6,9)):\n","        return 'summer'\n","    \n","    if month in list(range(9,12)):\n","        return 'autumn'\n","    \n","    else:\n","        return 'winter'\n","\n","data['review_season'] = data['review_season'].apply(get_season)\n","\n","# Кодируем признак методом OneHotEncoding:\n","\n","data = pd.get_dummies(data, columns=['review_season'])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Выделим сезонность оценок:\n","\n","fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 4))\n","\n","sns.countplot(data['review_month'], ax=axes[0]);\n","axes[0].set(xlabel='Месяц:', ylabel='Количество записей:')\n","axes[0].set_title('Распределение данных по месяцам:')\n","\n","sns.countplot(data['review_quarter'],  ax=axes[1]);\n","axes[1].set(xlabel='Квартал:', ylabel='Количество записей:')\n","axes[1].set_title('Распределение данных по кварталам:')\n","fig.show()"]},{"cell_type":"markdown","metadata":{},"source":["4.4 Иследуем признак 'tags' и создадим новый числовой признак ***'nights'*** - количество ночей в отеле:"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["data['tags'] = data['tags'].apply(\n","    lambda x: x.replace(\"[' \", \"\").replace(\" ']\", \"\").split(\" ', ' \"))\n","\n","def get_night(arg):\n","    \n","    for tag in arg:\n","        if 'Stayed' in tag:\n","            return int(tag.split()[1])\n","            \n","# Создание нового признака 'nights':\n","data['nights'] = data['tags'].apply(get_night)\n","\n","# Заменим пропуски в признаке медианой:\n","data['nights'] = data['nights'].fillna(data.nights.median())"]},{"cell_type":"markdown","metadata":{},"source":["4.5 Иследуем признак 'tags' и создадим новый числовой признак ***'type_trip'*** - тип поездки:"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Создание нового признака 'type_trip':\n","\n","data['type_trip'] = data['tags'].apply(\n","    lambda x: 1 if 'Business' in x else 0)"]},{"cell_type":"markdown","metadata":{},"source":["4.6 Иследуем признак 'tags' и создадим новый признак ***'type_of_travelers'*** - тип путешественников:"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def set_why_stayed(value):\n","    \n","    if 'Group' in  value:\n","        return 'Group'\n","    if 'Couple' in value:\n","        return 'Couple'  \n","    if 'Solo traveler' in value:\n","        return 'Solo traveler'\n","    if 'Family with young children' in value:\n","        return 'Family with young children'\n","    if 'Family with older children' in value:\n","        return 'Family with older children' \n","    return np.nan\n","\n","# Создание нового признака 'type_of_travelers':\n","\n","data['type_of_travelers'] = data['tags'].apply(set_why_stayed)\n","data['type_of_travelers'] = data['type_of_travelers'].fillna(\n","    data['type_of_travelers'].mode().iat[0])\n","\n","# Кодируем признак методом OneHotEncoding:\n","\n","data = pd.get_dummies(data, columns=['type_of_travelers'])"]},{"cell_type":"markdown","metadata":{},"source":["4.7 Иследуем признак 'tags' и создадим новый признак ***'type_of_apartment'*** - тип проживания:"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def get_room(arg):\n","    \n","    for tag in arg:\n","        if 'Room' in tag:\n","            return tag.strip()\n","    return 'Unknown'\n","            \n","# Создание нового признака 'type_of_apartment':\n","\n","data['type_of_apartment'] = data['tags'].apply(get_room)"]},{"cell_type":"markdown","metadata":{},"source":["4.8 Иследуем признак 'days_since_review' выделим числа:"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["data['days_since_review'] = data['days_since_review'].apply(\n","    lambda x: int(x.split()[0]))"]},{"cell_type":"markdown","metadata":{},"source":["4.9 Иследуем признак 'negative_review' и создадим числовой признак ***'is_negative'*** - отрицательные отзывы, которые не имеют отрицательного значения:"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Создание нового признака 'is_negative':\n","\n","data['is_negative'] = data['negative_review'].apply(\n","    lambda x: 0 if x == 'No Negative' else 1)"]},{"cell_type":"markdown","metadata":{},"source":["4.10 Иследуем признак 'positive_review' и создадим числовой признак ***'is_positive'*** - положительные отзывы, которые не имеют положительного значения:"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Создание нового признака 'is_positive':\n","\n","data['is_positive'] = data['positive_review'].apply(\n","    lambda x: 0 if x =='No Positive' else 1)"]},{"cell_type":"markdown","metadata":{},"source":["## **6. Отбор признаков:**\n","\n","6.1. Определим в данных неинформативные признаки, которые не будут участвовать в исследовании:"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Удаляем признаки которые еще не успели обработать, \n","# модель на признаках с dtypes \"object\" обучаться не будет,\n","# просто выберим их и удалим:\n","\n","object_columns = [s for s in data.columns if data[s].dtypes == 'object']\n","data.drop(object_columns, axis = 1, inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["data.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Теперь выделим тестовую часть:\n","\n","train_data = data.query('sample == 1').drop(['sample'], axis=1)\n","test_data = data.query('sample == 0').drop(['sample'], axis=1)\n","\n","y = train_data.reviewer_score.values            # наш таргет\n","X = train_data.drop(['reviewer_score'], axis=1)"]},{"cell_type":"markdown","metadata":{},"source":["## **7. Обучение модели**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Воспользуемся специальной функцие train_test_split\n","# для разбивки тестовых данных\n","# выделим 20% данных на валидацию (параметр test_size):\n","\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.2, random_state=RANDOM_SEED)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Проверяем:\n","\n","test_data.shape, train_data.shape, X.shape, X_train.shape, X_test.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Импортируем необходимые библиотеки:\n","# инструмент для создания и обучения модели:\n","\n","from sklearn.ensemble import RandomForestRegressor\n","\n","# инструменты для оценки точности модели:\n","\n","from sklearn import metrics"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Создаём модель (НАСТРОЙКИ НЕ ТРОГАЕМ):\n","\n","model = RandomForestRegressor(\n","    n_estimators=100, verbose=1, n_jobs=-1, random_state=RANDOM_SEED)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Обучаем модель на тестовом наборе данных:\n","\n","model.fit(X_train, y_train)\n","\n","# Используем обученную модель для предсказания\n","# рейтинга ресторанов в тестовой выборке.\n","# Предсказанные значения записываем в переменную y_pred:\n","\n","y_pred = model.predict(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Сравниваем предсказанные значения (y_pred) с реальными (y_test),\n","# и смотрим насколько они в среднем отличаются\n","# Метрика называется Mean Absolute Error (MAE) и показывает\n","# среднее отклонение предсказанных значений от фактических.\n","\n","print('MAPE:', metrics.mean_absolute_error(y_test, y_pred))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# в RandomForestRegressor есть возможность вывести\n","# самые важные признаки для модели:\n","\n","plt.rcParams['figure.figsize'] = (10,10)\n","feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n","feat_importances.nlargest(15).plot(kind='barh')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["test_data.sample(10)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["test_data = test_data.drop(['reviewer_score'], axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["sample_submission"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["predict_submission = model.predict(test_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["predict_submission"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["list(sample_submission)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["sample_submission['reviewer_score'] = predict_submission\n","sample_submission.to_csv('submission.csv', index=False)\n","sample_submission.head(10)"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":3207826,"sourceId":34288,"sourceType":"competition"}],"dockerImageVersionId":30157,"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.10"}},"nbformat":4,"nbformat_minor":4}
