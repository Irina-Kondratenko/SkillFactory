{"cells":[{"cell_type":"markdown","metadata":{},"source":["## **Задание 9.5. Модуль ML-6 (HW-03)**\n","\n","---\n","\n","Обучите модель линейной регрессии на найденных двумя способами трёх важных признаках и сравните полученные результаты. Загрузите полученный ноутбук (в формате IPYNB) в форму ниже.\n","\n","***КРИТЕРИИ ОЦЕНИВАНИЯ:***\n","\n","**1 балл** - Верно выделены три столбца-признака для обучения, выбранные RFE.  \n","**1 балл** - Верно выделены три столбца-признака для обучения, выбранные SelectKBest.  \n","**3 балла** - Обучена регрессия на первых трёх столбцах, оценено качество модели на тесте.  \n","**3 балла** - Обучена регрессия на вторых трёх столбцах, оценено качество модели на тесте.  \n","**2 балла** - Произведено сравнение выбранных метрик в форме комментария. Дан ответ на вопрос «Какой метод отбора признаков показал наилучший результат на тестовой выборке?» (в текстовой ячейке). \n","\n","Максимальное количество баллов за выполнение задания — 10.\n","\n"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"t_IvORKWGuCH"},"outputs":[],"source":["import pandas as pd\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LinearRegression\n","from sklearn.metrics import mean_absolute_error"]},{"cell_type":"markdown","metadata":{"id":"FtTudvkQGzRk"},"source":["# Загрузка данных:"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"gmll87tAG2rK"},"outputs":[],"source":["data = pd.read_excel('Data\\data_ford_price.xlsx') "]},{"cell_type":"markdown","metadata":{"id":"zKZZVz_6IA1m"},"source":["#  Отбор признаков: мотивация"]},{"cell_type":"markdown","metadata":{"id":"dt3vhRQ2G_uP"},"source":["## Предобработка данных:"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"CJdK-t3MHDSp"},"outputs":[],"source":["data = data[['price','year', 'cylinders', 'odometer', 'lat', 'long', 'weather']]\n","data.dropna(inplace = True)\n","\n","y = data['price']\n","x = data.drop(columns ='price')\n","\n","X_train, X_test, y_train, y_test = train_test_split(\n","    x, y, test_size=0.3, random_state=40)"]},{"cell_type":"markdown","metadata":{"id":"kqjEj0ABG4ZD"},"source":["## Обучение модели:"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1650361775695,"user":{"displayName":"Ketrin Trofimova","userId":"05400058012601189465"},"user_tz":-180},"id":"K0aIWfwpHSHN","outputId":"9d5779ab-7fea-43e4-f7d6-62317dfcc079"},"outputs":[{"name":"stdout","output_type":"stream","text":["MAE: 4682.957\n"]}],"source":["model = LinearRegression()\n","model.fit(X_train, y_train)\n","y_predicted = model.predict(X_test)\n"," \n","mae = mean_absolute_error(y_test, y_predicted)\n","print('MAE: %.3f' % mae)"]},{"cell_type":"markdown","metadata":{"id":"TznnlORnHisT"},"source":["## Удаление избыточного признака:"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":434,"status":"ok","timestamp":1650361779668,"user":{"displayName":"Ketrin Trofimova","userId":"05400058012601189465"},"user_tz":-180},"id":"pJQpOM9kHtSe","outputId":"709029e0-e13b-4f2b-92f7-9fa807a81b0f"},"outputs":[{"name":"stdout","output_type":"stream","text":["MAE: 4672.930\n"]}],"source":["x.drop('lat', axis = 1, inplace = True)\n","X_train, X_test, y_train, y_test = train_test_split(\n","    x, y, test_size=0.3, random_state=40)\n","model = LinearRegression()\n","model.fit(X_train, y_train)\n","y_predicted = model.predict(X_test)\n"," \n","mae = mean_absolute_error(y_test, y_predicted)\n","print('MAE: %.3f' % mae)"]},{"cell_type":"markdown","metadata":{"id":"E54vkz2xIGWm"},"source":["#  Отбор признаков: классификация методов"]},{"cell_type":"markdown","metadata":{"id":"dUnTavGgIpj0"},"source":["## Метод рекурсивного исключения признаков:"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"UYdiW0RWIZ5V"},"outputs":[{"name":"stdout","output_type":"stream","text":["MAE: 5113.445\n"]}],"source":["from sklearn.feature_selection import RFE\n","\n","# Выделим три наиболее значимых признака:\n","estimator = LinearRegression()\n","selector = RFE(estimator, n_features_to_select=3, step=1)\n","selector = selector.fit(X_train, y_train)\n"," \n","rfe = selector.get_feature_names_out()\n","\n","y = data['price']\n","x = data[rfe]\n","X_train, X_test, y_train, y_test = train_test_split(\n","    x, y, test_size=0.3, random_state=40)\n","\n","rfe_model = LinearRegression()\n","rfe_model = rfe_model.fit(X_train, y_train)\n","y_test_rfe = rfe_model.predict(X_test)\n","\n","mae = mean_absolute_error(y_test, y_test_rfe)\n","print('MAE: %.3f' % mae)"]},{"cell_type":"markdown","metadata":{"id":"_KhZgXCkK3Ap"},"source":["##  МЕТОДЫ ВЫБОРА ПРИЗНАКОВ НА ОСНОВЕ ФИЛЬТРОВ"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"mVHuMD0eK8or"},"outputs":[{"name":"stdout","output_type":"stream","text":["MAE: 5113.445\n"]}],"source":["from sklearn.feature_selection import SelectKBest, f_regression\n","SKB_model = LinearRegression()\n","selector = SelectKBest(f_regression, k=3)\n","selector.fit(X_train, y_train)\n","\n","X_train, X_test, y_train, y_test = train_test_split(\n","    x, y, test_size=0.3, random_state=40) \n","SKB = selector.get_feature_names_out()\n","\n","y = data['price']\n","x = data[SKB]\n","\n","SKB_model = SKB_model.fit(X_train, y_train)\n","y_test_SKB = SKB_model.predict(X_test)\n","\n","mae = mean_absolute_error(y_test, y_test_SKB)\n","print('MAE: %.3f' % mae)"]},{"cell_type":"markdown","metadata":{},"source":["Вывод: наилучший результат на тестовой выборке показал метод удаления избыточного признака."]}],"metadata":{"colab":{"collapsed_sections":[],"name":"Отбор_признаков.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.10"}},"nbformat":4,"nbformat_minor":0}
